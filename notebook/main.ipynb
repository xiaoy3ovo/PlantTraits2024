{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":65626,"databundleVersionId":8046133,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"实现DINOv2特征提取","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nfrom transformers import AutoImageProcessor, AutoModel\n\n# 配置类：设置路径、模型名称、图像大小和设备等参数\nclass CFG:\n    DATA_DIR = \"/kaggle/input/planttraits2024\"  # 数据集路径\n    TRAIN_IMAGES_DIR = os.path.join(DATA_DIR, \"train_images\")  # 训练图像路径\n    TEST_IMAGES_DIR = os.path.join(DATA_DIR, \"test_images\")  # 测试图像路径\n    OUTPUT_DIR = \"/kaggle/working/\"  # 嵌入保存路径\n\n    DINO_MODEL_NAME = \"facebook/dinov2-base\"  # 使用的DINOv2模型\n    IMAGE_SIZE = 224  # 图像尺寸\n    BATCH_SIZE = 64  # 批处理大小，依赖GPU内存\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # 设备选择\n\n# 加载CSV文件中的元数据\ntrain_df = pd.read_csv(os.path.join(CFG.DATA_DIR, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(CFG.DATA_DIR, \"test.csv\"))\n\n# 加载DINOv2图像处理器和模型\nprint(f\"Loading DINOv2 model: {CFG.DINO_MODEL_NAME} on device: {CFG.DEVICE}\")\nprocessor = AutoImageProcessor.from_pretrained(CFG.DINO_MODEL_NAME)\nmodel = AutoModel.from_pretrained(CFG.DINO_MODEL_NAME).to(CFG.DEVICE).eval()\n\n# 构造图像路径的函数\ndef get_image_path(image_id, is_test=False):\n    base_dir = CFG.TEST_IMAGES_DIR if is_test else CFG.TRAIN_IMAGES_DIR\n    return os.path.join(base_dir, f\"{image_id}.jpeg\")\n\n# 提取图像嵌入的函数\ndef extract_embeddings(df, is_test=False):\n    image_paths = df['id'].apply(lambda x: get_image_path(x, is_test)).tolist()\n    all_embeddings = []\n\n    # 按批处理图像以节省内存\n    for i in tqdm(range(0, len(image_paths), CFG.BATCH_SIZE), desc=f\"Extracting {'Test' if is_test else 'Train'} Embeddings\"):\n        batch_paths = image_paths[i : i + CFG.BATCH_SIZE]\n\n        try:\n            images = [Image.open(p).convert(\"RGB\") for p in batch_paths]\n            inputs = processor(images=images, return_tensors=\"pt\").to(CFG.DEVICE)\n        except Exception as e:\n            print(f\"Error loading batch starting at index {i}: {e}\")\n            batch_size = len(batch_paths)\n            embedding_dim = model.config.hidden_size\n            placeholder_embeddings = np.zeros((batch_size, embedding_dim))\n            all_embeddings.append(placeholder_embeddings)\n            continue\n\n        # 执行前向推理\n        with torch.no_grad():\n            outputs = model(**inputs)\n            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # 提取CLS token输出\n            all_embeddings.append(batch_embeddings)\n\n    return np.vstack(all_embeddings)\n\n# 提取训练集嵌入并保存\nprint(\"Starting Train Embedding Extraction...\")\ntrain_embeddings = extract_embeddings(train_df, is_test=False)\ntrain_embedding_path = os.path.join(CFG.OUTPUT_DIR, \"train_dino_embeddings.npy\")\nnp.save(train_embedding_path, train_embeddings)\nprint(f\"Train embeddings saved to {train_embedding_path}, shape: {train_embeddings.shape}\")\n\n# 提取测试集嵌入并保存\nprint(\"\\nStarting Test Embedding Extraction...\")\ntest_embeddings = extract_embeddings(test_df, is_test=True)\ntest_embedding_path = os.path.join(CFG.OUTPUT_DIR, \"test_dino_embeddings.npy\")\nnp.save(test_embedding_path, test_embeddings)\nprint(f\"Test embeddings saved to {test_embedding_path}, shape: {test_embeddings.shape}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"数据预处理","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom tqdm.auto import tqdm\nimport pandas as pd\nimport numpy as np\nimport os\nimport torch\n\n# 配置类：定义路径和设备\nclass CFG:\n    DATA_DIR = \"/kaggle/input/planttraits2024\"  # 原始数据路径\n    OUTPUT_DIR = \"/kaggle/working/\"  # 输出路径\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # 是否使用GPU\n\n# 加载训练和测试数据\nprint(\"Loading data from CSV files...\")\ntrain_df = pd.read_csv(os.path.join(CFG.DATA_DIR, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(CFG.DATA_DIR, \"test.csv\"))\nprint(\"Data loaded successfully.\")\n\n# 定义表格特征处理配置\nclass TabularCFG:\n    TARGET_BASE_COLS = ['X4', 'X11', 'X18', 'X26', 'X50', 'X3112']  # 目标列\n    SKEWED_TARGETS = ['X11', 'X18', 'X26', 'X50', 'X3112']  # 偏态目标列\n\n    OUTLIER_CLIP_LOWER_QUANTILE = 0.005  # 异常值下界分位数\n    OUTLIER_CLIP_UPPER_QUANTILE = 0.995  # 异常值上界分位数\n    POLYNOMIAL_DEGREE = 2  # 多项式扩展次数\n\n# 设置表格特征列（排除 id）\nTabularCFG.TABULAR_FEATURES = [\n    col for col in test_df.columns if col != 'id'\n]\n\n# 开始表格特征处理流水线\nprint(\"\\nStarting data processing pipeline...\")\n\n# 对偏态目标变量做 log1p 变换\nprint(\"Applying log1p transformation to skewed target variables...\")\nfor trait in TabularCFG.SKEWED_TARGETS:\n    train_df[f'{trait}_log'] = np.log1p(train_df[f'{trait}_mean'])\n\n# 对特征值做 clip，处理异常值\nprint(f\"Clipping features...\")\nfor col in tqdm(TabularCFG.TABULAR_FEATURES, desc=\"Calculating Clip Bounds\"):\n    lower = train_df[col].quantile(TabularCFG.OUTLIER_CLIP_LOWER_QUANTILE)\n    upper = train_df[col].quantile(TabularCFG.OUTLIER_CLIP_UPPER_QUANTILE)\n    train_df[col] = train_df[col].clip(lower, upper)\n    test_df[col] = test_df[col].clip(lower, upper)\n\n# 多项式特征扩展（包括二次项和交叉项）\nprint(f\"Generating polynomial features...\")\npoly = PolynomialFeatures(degree=TabularCFG.POLYNOMIAL_DEGREE, include_bias=False, interaction_only=False)\ntrain_poly_features = poly.fit_transform(train_df[TabularCFG.TABULAR_FEATURES])\ntest_poly_features = poly.transform(test_df[TabularCFG.TABULAR_FEATURES])\n\n# 将生成的多项式特征转换为DataFrame\npoly_feature_names = poly.get_feature_names_out(TabularCFG.TABULAR_FEATURES)\ntrain_poly_df = pd.DataFrame(train_poly_features, columns=poly_feature_names, index=train_df.index)\ntest_poly_df = pd.DataFrame(test_poly_features, columns=poly_feature_names, index=test_df.index)\n\n# 标准化处理（Z-score）\nprint(\"Applying Z-score standardization...\")\nscaler = StandardScaler()\ntrain_tabular_scaled = scaler.fit_transform(train_poly_df)\ntest_tabular_scaled = scaler.transform(test_poly_df)\n\n# 保存处理后的表格数据为 .npy 文件\nprint(\"\\nSaving processed tabular data...\")\ntrain_tabular_path = os.path.join(CFG.OUTPUT_DIR, \"train_tabular_processed.npy\")\ntest_tabular_path = os.path.join(CFG.OUTPUT_DIR, \"test_tabular_processed.npy\")\nnp.save(train_tabular_path, train_tabular_scaled)\nnp.save(test_tabular_path, test_tabular_scaled)\n\nprint(f\"Processed tabular data saved.\")\nprint(f\"Train shape: {train_tabular_scaled.shape}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"模型训练、推断和提交","metadata":{}},{"cell_type":"code","source":"import gc\nimport catboost\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import r2_score\nimport pandas as pd\nimport numpy as np\nimport os\nimport torch\n\n# 配置类：用于存储常量路径和设备信息\nclass CFG:\n    DATA_DIR = \"/kaggle/input/planttraits2024\"  # 数据路径\n    OUTPUT_DIR = \"/kaggle/working/\"  # 输出路径\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # 判断是否使用GPU\n\n# 配置类：存储目标变量和偏斜变量名称\nclass TabularCFG:\n    TARGET_COLS = ['X4', 'X11', 'X18', 'X26', 'X50', 'X3112']\n    SKEWED_TARGETS = ['X11', 'X18', 'X26', 'X50', 'X3112']  # 偏态变量\n\n# 加载预处理后的数据\nprint(\"Loading pre-processed features for Stage 2 modeling...\")\ntrain_df = pd.read_csv(os.path.join(CFG.DATA_DIR, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(CFG.DATA_DIR, \"test.csv\"))\n\n# 对偏态变量进行log1p变换\nfor trait in TabularCFG.SKEWED_TARGETS:\n    train_df[f'{trait}_log'] = np.log1p(train_df[f'{trait}_mean'])\n\n# 加载图像嵌入和表格特征\ntrain_embeddings = np.load(os.path.join(CFG.OUTPUT_DIR, \"train_dino_embeddings.npy\"))\ntest_embeddings = np.load(os.path.join(CFG.OUTPUT_DIR, \"test_dino_embeddings.npy\"))\ntrain_tabular_scaled = np.load(os.path.join(CFG.OUTPUT_DIR, \"train_tabular_processed.npy\"))\ntest_tabular_scaled = np.load(os.path.join(CFG.OUTPUT_DIR, \"test_tabular_processed.npy\"))\n\n# 数据融合：将图像嵌入和表格特征组合为一个DataFrame\nprint(\"Fusing image embeddings and tabular features into a DataFrame...\")\nnum_tabular_features = train_tabular_scaled.shape[1]\ntabular_cols = [f'tab_{i}' for i in range(num_tabular_features)]\nX = pd.DataFrame(train_tabular_scaled, columns=tabular_cols)\nX_test = pd.DataFrame(test_tabular_scaled, columns=tabular_cols)\nX['dino_embedding'] = list(train_embeddings)\nX_test['dino_embedding'] = list(test_embeddings)\n\nprint(f\"Final training feature matrix shape: {X.shape}\")\nprint(f\"Final test feature matrix shape: {X_test.shape}\")\nprint(\"Feature format after fusion:\")\nprint(X.head())\n\n# 清理不再需要的变量释放内存\ndel train_embeddings, test_embeddings, train_tabular_scaled, test_tabular_scaled\ngc.collect()\n\n# 模型训练配置\nclass ModelCFG:\n    N_SPLITS = 5\n    SEED = 42\n    CATBOOST_PARAMS = {\n        'iterations': 2000,\n        'learning_rate': 0.03,\n        'depth': 6,\n        'l2_leaf_reg': 3.0,\n        'loss_function': 'RMSE',\n        'eval_metric': 'R2',\n        'random_seed': SEED,\n        'verbose': 0,\n        'early_stopping_rounds': 50,\n        'embedding_features': ['dino_embedding'],  # 指定嵌入列名\n        'task_type': 'GPU' if CFG.DEVICE == 'cuda' else 'CPU'\n    }\n\nkf = KFold(n_splits=ModelCFG.N_SPLITS, shuffle=True, random_state=ModelCFG.SEED)\noof_preds = {}\ntest_preds = {}\noof_scores = {}\n\n# 初始化预测字典\nfor trait in TabularCFG.TARGET_COLS:\n    oof_preds[trait] = np.zeros(len(train_df))\n    test_preds[trait] = np.zeros(len(test_df))\n\n# 主训练循环\nplot_learning_curve_done = False \nfor fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n    print(f\"\\n===== FOLD {fold+1} / {ModelCFG.N_SPLITS} =====\")\n    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n\n    for trait in TabularCFG.TARGET_COLS:\n        print(f\"--- Training model for trait: {trait} ---\")\n        is_log_target = trait in TabularCFG.SKEWED_TARGETS\n        target_col = f'{trait}_log' if is_log_target else f'{trait}_mean'\n\n        y = train_df[target_col] \n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n        model = catboost.CatBoostRegressor(**ModelCFG.CATBOOST_PARAMS)\n        model.fit(\n            X_train, y_train,\n            eval_set=[(X_train, y_train), (X_val, y_val)],\n            use_best_model=True\n        )\n\n        # 仅第一次绘制学习曲线\n        if not plot_learning_curve_done:\n            import matplotlib.pyplot as plt\n            import seaborn as sns\n            sns.set_style(\"darkgrid\")\n            evals_result = model.get_evals_result()\n            train_r2 = evals_result['learn']['R2']\n            val_r2 = evals_result['validation']['R2']\n            epochs = range(1, len(train_r2) + 1)\n            plt.figure(figsize=(12, 7))\n            plt.plot(epochs, train_r2, 'b-', label='Train R2')\n            plt.plot(epochs, val_r2, 'o-', label='Validation R2')\n            plt.title(f'Learning Curve for Trait \"{trait}\" (Fold {fold+1})')\n            plt.xlabel('Iterations')\n            plt.ylabel('R2 Score')\n            plt.legend()\n            plt.show()\n            plot_learning_curve_done = True\n\n# 第二轮训练+预测（逻辑与前相同）\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n    print(f\"\\n===== FOLD {fold+1} / {ModelCFG.N_SPLITS} =====\")\n    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx] \n\n    for trait in TabularCFG.TARGET_COLS:\n        print(f\"--- Training model for trait: {trait} ---\")\n        is_log_target = trait in TabularCFG.SKEWED_TARGETS\n        target_col = f'{trait}_log' if is_log_target else f'{trait}_mean'\n\n        y = train_df[target_col] \n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n        model = catboost.CatBoostRegressor(**ModelCFG.CATBOOST_PARAMS)\n        model.fit(\n            X_train, y_train,\n            eval_set=(X_val, y_val),\n            use_best_model=True\n        )\n\n        val_preds = model.predict(X_val)\n        fold_test_preds = model.predict(X_test)\n\n        oof_preds[trait][val_idx] = val_preds\n        test_preds[trait] += fold_test_preds / ModelCFG.N_SPLITS\n\n    del X_train, X_val\n    gc.collect()\n\n# 输出交叉验证R2得分\nprint(\"\\n===== OOF R2 SCORES =====\")\nfor trait in TabularCFG.TARGET_COLS:\n    is_log_target = trait in TabularCFG.SKEWED_TARGETS\n    true_values = train_df[f'{trait}_mean'].values\n    pred_values = np.expm1(oof_preds[trait]) if is_log_target else oof_preds[trait]\n    score = r2_score(true_values, pred_values)\n    oof_scores[trait] = score\n    print(f\"Trait {trait}: {score:.4f}\")\n\navg_oof_score = np.mean(list(oof_scores.values()))\nprint(f\"\\nAverage OOF R2 Score: {avg_oof_score:.4f}\")\n\n# 创建提交文件\nprint(\"\\nCreating submission file...\")\nsubmission_df = pd.DataFrame({'id': test_df['id']})\nfor trait in TabularCFG.TARGET_COLS:\n    is_log_target = trait in TabularCFG.SKEWED_TARGETS\n    submission_df[trait] = np.expm1(test_preds[trait]) if is_log_target else test_preds[trait]\n\n# 防止负值\nfor trait in TabularCFG.TARGET_COLS:\n    submission_df[trait] = submission_df[trait].clip(lower=0)\n\nsubmission_path = os.path.join(CFG.OUTPUT_DIR, 'submission.csv')\nsubmission_df.to_csv(submission_path, index=False)\n\nprint(f\"Submission file saved to {submission_path}\")\nprint(submission_df.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}